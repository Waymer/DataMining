---
title: "Writeup"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Unsupervised Learning

```{r}
load("TrainData.Rdata")

X <- read.table(file="trainX.txt",header=TRUE)
y <- read.table(file="trainy.txt",header=TRUE)

# PCA
x <- data.matrix(trainX)
pc <- prcomp(x)
plot(cumsum(pc$sdev^2/sum(pc$sdev^2))) #cumulative explained variance

# K-Means
k2 <- kmeans(pc$x[,1:10], centers = 2, iter.max = 100, nstart = 10, 
                algorithm = "Lloyd")
x_df <- data.frame(pc$x[,1:10], cluster = as.factor((k2$cluster - 2)*-1))

sum(x_df$cluster != trainY) / 133

# Hierarchical Clustering
hcluster <- hclust(dist(data.frame(pc$x[,1:10])), method = "average")
plot(hcluster)
```

# Hierarchical Clustering

```{r}
k2 <- kmeans(res$x[,1:10], centers = 2, iter.max = 100, nstart = 10, 
                algorithm = "Lloyd")
x_df <- data.frame(res$x[,1:10], cluster = as.factor((k2$cluster - 2)*-1))

#Average Linkage
acluster <- hclust(dist(data.frame(x_df)), method = "average")
plot(acluster)
aclusterCut <- cutree(acluster, 3)
sum(aclusterCut != trainY) / 133

#Single Linkage
scluster <- hclust(dist(data.frame(x_df)), method = "single")
plot(scluster)
sclusterCut <- cutree(scluster, 3)
sum(sclusterCut != trainY) / 133

#Complete Linkage
ccluster <- hclust(dist(data.frame(x_df)), method = "complete")
plot(ccluster)
cclusterCut <- cutree(ccluster, 3)
sum(cclusterCut != trainY) / 133

#We can see that each method, Complete, Single, and Average all yield rather similar results. The branches have poor distribution, so cutting at small levels like 3 would give wildly inconsistent groupings, with one group with few elements and another with many. We also see from the error rates that each of these hierarchical clustering methods have high errors, all above 80%. Because of these issues, hierarchical clustering is likely suboptimal for this context. 
```