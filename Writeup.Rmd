---
title: "Writeup"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Unsupervised Learning

```{r}
load("TrainData.Rdata")

X <- read.table(file="trainX.txt",header=TRUE)
y <- read.table(file="trainy.txt",header=TRUE)

# PCA
x <- data.matrix(trainX)
pc <- prcomp(x)
plot(cumsum(pc$sdev^2/sum(pc$sdev^2))) #cumulative explained variance

# K-Means
k2 <- kmeans(pc$x[,1:10], centers = 2, iter.max = 100, nstart = 10, 
                algorithm = "Lloyd")
x_df <- data.frame(pc$x[,1:10], cluster = as.factor((k2$cluster - 2)*-1))

sum(x_df$cluster != trainY) / 133

# Hierarchical Clustering
hcluster <- hclust(dist(data.frame(pc$x[,1:10])), method = "average")
plot(hcluster)
```

# Hierarchical Clustering

```{r}
k2 <- kmeans(res$x[,1:10], centers = 2, iter.max = 100, nstart = 10, 
                algorithm = "Lloyd")
x_df <- data.frame(res$x[,1:10], cluster = as.factor((k2$cluster - 2)*-1))

#Average Linkage
acluster <- hclust(dist(data.frame(x_df)), method = "average")
plot(acluster, main = "Average Hierarchical Clustering", xlab = "")
aclusterCut <- cutree(acluster, 2)
aclusterCut[aclusterCut == 1] = 0
aclusterCut[aclusterCut == 2] = 1
print("Average Hierarchical Classifcation Error: "); sum(aclusterCut != trainY) / 133

#Single Linkage
scluster <- hclust(dist(data.frame(x_df)), method = "single")
plot(scluster, main = "Single Hierarchical Clustering", xlab = "")
sclusterCut <- cutree(scluster, 2)
sclusterCut[sclusterCut == 1] = 0
sclusterCut[sclusterCut == 2] = 1
print("Single Hierarchical Classifcation Error: "); sum(sclusterCut != trainY) / 133

#Complete Linkage
ccluster <- hclust(dist(data.frame(x_df)), method = "complete")
plot(ccluster, main = "Complete Hierarchical Clustering", xlab = "")
cclusterCut <- cutree(ccluster, 2)
cclusterCut[cclusterCut == 1] = 0
cclusterCut[cclusterCut == 2] = 1
print("Complete Hierarchical Classifcation Error: "); sum(cclusterCut != trainY) / 133

#We can see that each method, Complete, Single, and Average all yield rather similar results. The branches have poor distribution, so cutting at small levels like 3 would give wildly inconsistent groupings, with one group with few elements and another with many. However, this does not necessarily mean this clustering method would be inappropriate for this context. Taking a closer look at the errors, we see that the classification errors are actually somewhat low. Average linkage has the lowest error, while single has the highest error. With an error of ~12.8%, average hierarchical clustering is a viable method for this problem. 
```